# -*- coding: utf-8 -*-
"""nvidia_modulus_ns_stokes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/ronmaccms/macadThesis24/blob/main/src/PINN_Tests/nvidia_modulus_ns_stokes.ipynb

# Install NVIDIA Modulus
"""

!pip install nvidia-modulus nvidia-modulus-sym

"""# Import Required Libraries"""

import os
import warnings
import torch
import numpy as np
import matplotlib.pyplot as plt
from sympy import Symbol, Eq, Abs

"""For educational purposes, we will actually import the NVIDIA Modulus modules in parts as we need them.

But you can import them from the beginning like this.
"""

# import modulus.sym
# from modulus.sym.hydra import to_absolute_path, instantiate_arch, ModulusConfig
# from modulus.sym.solver import Solver
# from modulus.sym.domain import Domain
# from modulus.sym.geometry.primitives_2d import Rectangle
# from modulus.sym.domain.constraint import (
#     PointwiseBoundaryConstraint,
#     PointwiseInteriorConstraint,
#     # PointwiseConstraint
# )
# # from modulus.sym.domain.validator import PointwiseValidator
# from modulus.sym.domain.inferencer import PointwiseInferencer
# from modulus.sym.key import Key
# from modulus.sym.eq.pdes.navier_stokes import NavierStokes
# from modulus.sym.utils.io import (
#     csv_to_dict,
#     ValidatorPlotter,
#     InferencerPlotter
# )

"""# Navier Stokes PDEs

I recommend you check out the GitHub repository of NVIDIA modulus where this equation is defined:

https://github.com/NVIDIA/modulus-sym/blob/main/modulus/sym/eq/pdes/navier_stokes.py
"""

from modulus.sym.eq.pdes.navier_stokes import NavierStokes

ns = NavierStokes(nu=0.01, rho=1.0, dim=2, time=False)

ns.equations

ns.pprint()

ns.equations['continuity']

ns.equations['momentum_x']

ns.equations['momentum_y']

"""# Neural Network

The docs recommend defining the neural network architecture with a configuration file:

https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/basics/lid_driven_cavity_flow.html#creating-a-neural-network-node

But we'll do it with code ;)

This is because we want to understand what actually happens behind the scenes a little better, and that is why I also recommend you check out the `arch.py` file in the NVIDIA Modulus repository where the data classes are defined:

https://github.com/NVIDIA/modulus-sym/blob/f59eba4d852a65cc80f703da754a87e51ba44d9d/modulus/sym/hydra/arch.py#L94
"""

from modulus.sym.models.fully_connected import FullyConnectedArch
from modulus.sym.models.activation import Activation
from modulus.sym.key import Key

# Explicit declaration
flow_net = FullyConnectedArch(
    # Science & Engineering Knowledge
    input_keys=[Key("x"), Key("y")],
    output_keys=[Key("u"), Key("v"), Key("p")],
    # Neural Networks Knowledge (You don't need to know...)
    layer_size=512,
    nr_layers=6,
    skip_connections=False,
    activation_fn=Activation.SILU,
    adaptive_activations=False,
    weight_norm=True
)

flow_net

nodes = ns.make_nodes() + [flow_net.make_node(name="flow_network")]

nodes

"""# Geometry"""

from modulus.sym.geometry.primitives_2d import Rectangle

height = 0.1
width = 0.1
x, y = Symbol('x'), Symbol('y')
rec = Rectangle((-width/2, -height/2), (width/2, height/2))

rec

"""# Constraints

## Domain
"""

from modulus.sym.domain import Domain

ldc_domain = Domain()

"""## Boundary Constraints"""

from modulus.sym.domain.constraint import (
    PointwiseBoundaryConstraint,
    PointwiseInteriorConstraint,
    PointwiseConstraint
)

# top wall
top_wall = PointwiseBoundaryConstraint(
    nodes=nodes,
    geometry=rec,
    outvar={
        "u": 1.0, "v": 0
    },
    # batch_size=cfg.batch_size.TopWall
    batch_size=1000,
    lambda_weighting={"u": 1.0 - 20 * Abs(x), "v": 1.0},  # weight edges to be zero
    criteria=(Eq(y, height / 2))  # y = 0.05
)

# no slip
no_slip = PointwiseBoundaryConstraint(
    nodes=nodes,
    geometry=rec,
    outvar={
        "u": 0, "v": 0
    },
    batch_size=1000,
    criteria = y < height / 2
)

# science engineering here
ldc_domain.add_constraint(top_wall, "top_wall")
ldc_domain.add_constraint(no_slip, "no_slip")

"""## Interior Constraints"""

interior = PointwiseInteriorConstraint(
    nodes=nodes,
    geometry=rec,
    outvar={
        "continuity": 0, "momentum_x": 0, "momentum_y": 0
    },
    batch_size=4000,
    lambda_weighting={
        "continuity": Symbol("sdf"),
        "momentum_x": Symbol("sdf"),
        "momentum_y": Symbol("sdf")
    }
)
ldc_domain.add_constraint(interior, "interior")
ldc_domain.add_constraint(interior, "interior")

"""https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/basics/lid_driven_cavity_flow.html#creating-a-neural-network-node


# Solver Configuration

The user guide shows how to convert a configuration file into a configuration object.

https://docs.nvidia.com/deeplearning/modulus/modulus-sym-v110/notebook.nbconvert.html
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile config.yaml
# 
# defaults:
#   - modulus_default
#   - arch: fully_connected
#   - scheduler: tf_exponential_lr
#   - optimizer: adam
#   - loss: sum
#   - _self_
# 
# scheduler:
#   decay_rate: 0.95
#   decay_steps: 4000
# 
# training:
#   rec_validation_freq: 1000
#   rec_inference_freq: 2000
#   rec_monitor_freq: 1000
#   rec_constraint_freq: 2000
#   max_steps: 10000
# 
# batch_size:
#   TopWall: 1000
#   NoSlip: 1000
#   Interior: 4000
# 
# graph:
#   func_arch: true
#

import modulus.sym
from modulus.sym.hydra import to_yaml
from modulus.sym.hydra.utils import compose
from modulus.sym.hydra.config import ModulusConfig

cfg = compose(config_path=".", config_name="config")
cfg.network_dir = 'outputs' # Set the network directory for checkpoints
print(to_yaml(cfg))

"""# Create Solver"""

from modulus.sym.solver import Solver

slv = Solver(cfg, ldc_domain)

"""# Run Solver

First configure the logging to see the steps!
"""

import logging

# Create a function to configure logging
def configure_logging():
    # Get the root logger
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    # Remove all existing handlers
    while logger.handlers:
        logger.handlers.pop()

    # Create a stream handler
    stream_handler = logging.StreamHandler()
    stream_handler.setLevel(logging.DEBUG)

    # Create a formatter
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    stream_handler.setFormatter(formatter)

    # Add the handler to the logger
    logger.addHandler(stream_handler)

# Configure logging
configure_logging()

# Test logging
logging.debug("Logging is configured correctly.")

# slv.solve()

"""# Output Files

## Load Model From File
"""

torch.load('./outputs/optim_checkpoint.0.pth').keys()

torch.load('./outputs/flow_network.0.pth').keys()

# checkpoint = torch.load('./outputs/optim_checkpoint.0.pth')
checkpoint = torch.load('./outputs/flow_network.0.pth')
try:
    checkpoint.eval()
except AttributeError as error:
    print(error)

# https://stackoverflow.com/a/51812173/8062488 (simiar to this, but not exactly)
# flow_net.load_state_dict(checkpoint['state_dict'])

flow_net.load_state_dict(checkpoint)

"""## How to evaluate a PyTorch model"""

flow_net

"""```
FullyConnectedArch: def _wrapped_call_impl(*args, **kwargs)
Activation.SILU  
[N, size]
[N, size]
>>> arch = .fully_connected.FullyConnectedArch(
>>>    [Key("x", size=2)],
>>>    [Key("y", size=2)],
>>>    layer_size = 64,
>>>    nr_layers = 2)
>>> model = arch.make_node()
>>> input = {"x": torch.randn(64, 2)}
>>> output = model.evaluate(input)
>>> arch = .fully_connected.FullyConnectedArch(
>>>    [Key("x", size=2)],
>>>    [Key("y", size=2)],
>>>    periodicity={'x': (0, 1)})
```
"""

# Example
arch = FullyConnectedArch(
[Key("x", size=2)], # input layer has two values, or is an "x" of dimension 2
[Key("y", size=2)], # output layers also outputs the same kind of thig here
layer_size = 64,
nr_layers = 2)
model = arch.make_node(name="test_model")
input = {"x": torch.randn(10, 2)}
output = model.evaluate(input)
output

arch(input)

torch.randn(10, 2)

"""# How to evaluate **OUR** PyTorch flow model

This is why we instantiated it like this.

```
flow_net = FullyConnectedArch(
    input_keys=[Key("x"), Key("y")],
    output_keys=[Key("u"), Key("v"), Key("p")],
    layer_size=512,
    nr_layers=6,
    skip_connections=False,
    activation_fn=Activation.SILU,
    adaptive_activations=False,
    weight_norm=True,
)
```
"""

torch.randn(5, 1)

torch.tensor([0.04])

torch.rand(5, 1)

# A top wall point (x,y) = [0, 0.05]
flow_net({"x": torch.tensor([0]), "y": torch.tensor([0.05])} )

(torch.rand(5, 1) * 0.1) - 0.05

flow_net({"x": (torch.rand(5, 1) * 0.1) -0.05, "y": (torch.rand(5, 1) * 0.1) -0.05} )

flow_net({"x": torch.tensor([0.05]), "y": torch.tensor([0])} )

"""# Finally, how to visualize our results"""

# Define the domain
x_values = np.linspace(-0.05, 0.05, 100)
y_values = np.linspace(-0.05, 0.05, 100)
x_grid, y_grid = np.meshgrid(x_values, y_values)

# Flatten the grid arrays to create inputs for the model
x_flat = x_grid.flatten()
y_flat = y_grid.flatten()

# Convert to PyTorch tensors
x_tensor = torch.tensor(x_flat, dtype=torch.float32).unsqueeze(1)
y_tensor = torch.tensor(y_flat, dtype=torch.float32).unsqueeze(1)

# Create input dictionary for the model
inputs = {"x": x_tensor, "y": y_tensor}

# Pass inputs through the model to get predictions
outputs = flow_net(inputs)
u_flat = outputs['u'].detach().numpy()
v_flat = outputs['v'].detach().numpy()
p_flat = outputs['p'].detach().numpy()

# Reshape the outputs back to grid shape
u_grid = u_flat.reshape(x_grid.shape)
v_grid = v_flat.reshape(x_grid.shape)
p_grid = p_flat.reshape(x_grid.shape)

# Plot the color maps
fig, axs = plt.subplots(1, 3, figsize=(18, 6))

# Plot p
im0 = axs[0].imshow(p_grid, extent=[-0.05, 0.05, -0.05, 0.05], origin='lower', aspect='auto')
axs[0].set_title('p')
axs[0].set_xlabel('x')
axs[0].set_ylabel('y')
fig.colorbar(im0, ax=axs[0])

# Plot u
im1 = axs[1].imshow(u_grid, extent=[-0.05, 0.05, -0.05, 0.05], origin='lower', aspect='auto')
axs[1].set_title('u')
axs[1].set_xlabel('x')
axs[1].set_ylabel('y')
fig.colorbar(im1, ax=axs[1])

# Plot v
im2 = axs[2].imshow(v_grid, extent=[-0.05, 0.05, -0.05, 0.05], origin='lower', aspect='auto')
axs[2].set_title('v')
axs[2].set_xlabel('x')
axs[2].set_ylabel('y')
fig.colorbar(im2, ax=axs[2])

plt.tight_layout()
plt.show()

# Define the domain
x_values = np.linspace(-0.05, 0.05, 20)  # Reduced number of points for clearer vector field
y_values = np.linspace(-0.05, 0.05, 20)
x_grid, y_grid = np.meshgrid(x_values, y_values)

# Flatten the grid arrays to create inputs for the model
x_flat = x_grid.flatten()
y_flat = y_grid.flatten()

# Convert to PyTorch tensors
x_tensor = torch.tensor(x_flat, dtype=torch.float32).unsqueeze(1)
y_tensor = torch.tensor(y_flat, dtype=torch.float32).unsqueeze(1)

# Create input dictionary for the model
inputs = {"x": x_tensor, "y": y_tensor}

# Pass inputs through the model to get predictions
outputs = flow_net(inputs)
u_flat = outputs['u'].detach().numpy()
v_flat = outputs['v'].detach().numpy()

# Reshape the outputs back to grid shape
u_grid = u_flat.reshape(x_grid.shape)
v_grid = v_flat.reshape(x_grid.shape)

# Plot the vector field
plt.figure(figsize=(8, 6))
plt.quiver(x_grid, y_grid, u_grid, v_grid, scale=10, color='blue')  # Adjust scale as needed
plt.title('Vector Field of u and v')
plt.xlabel('x')
plt.ylabel('y')
plt.xlim([-0.05, 0.05])
plt.ylim([-0.05, 0.05])
plt.grid(True)
plt.show()

# Calculate the magnitude of the vectors
magnitude = np.sqrt(u_grid**2 + v_grid**2)

# Plot the vector field with colors
plt.figure(figsize=(8, 6))
plt.quiver(x_grid, y_grid, u_grid, v_grid, magnitude, scale=10, cmap='viridis')  # Adjust scale as needed
plt.colorbar(label='Magnitude')
plt.title('Vector Field of u and v')
plt.xlabel('x')
plt.ylabel('y')
plt.xlim([-0.05, 0.05])
plt.ylim([-0.05, 0.05])
plt.grid(True)
plt.show()

# Plot streamlines
plt.figure(figsize=(8, 6))
plt.streamplot(x_grid, y_grid, u_grid, v_grid, color=magnitude, cmap='viridis')
plt.colorbar(label='Magnitude')
plt.title('Streamlines of u and v')
plt.xlabel('x')
plt.ylabel('y')
plt.xlim([-0.05, 0.05])
plt.ylim([-0.05, 0.05])
plt.grid(True)
plt.show()